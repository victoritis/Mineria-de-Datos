{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IH7LS4vMFFKi"
   },
   "source": [
    "## Descripción de la práctica\n",
    "\n",
    "En esta práctica se va a utilizar Sklearn para entrenar y probar modelos de clasificación y regresión.\n",
    "\n",
    "En el caso de clasificación se van a usar:\n",
    "- Los datos de la práctica 1 de KNIME, el conjunto completo.\n",
    "- Heart Failure.\n",
    "- Wisconsin Breast Cancer\n",
    "\n",
    "En el caso de regresión se van a utilizar los conjuntos de datos:\n",
    "- Diabetes\n",
    "- Insurance\n",
    "- Life expectancy WHO.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Af5Sr7rOFFKj"
   },
   "source": [
    "## Descripción de los datos\n",
    "\n",
    "### Datos de clasificación\n",
    "\n",
    "La descripción de los datos se puede consultar en los siguientes lugares.\n",
    "\n",
    "- Heart Failure.  https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records\n",
    "- Wisconsin Breast Cancer https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "- Diabetes https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "- Insurance https://www.kaggle.com/datasets/mirichoi0218/insurance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbmWulUxFFKf"
   },
   "source": [
    "<img style=\"float:left\" width=\"70%\" src=\"pics/escudo_COLOR_1L_DCHA.png\">\n",
    "<img style=\"float:right\" width=\"15%\" src=\"pics/PythonLogo.svg\">\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Minería de datos\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Práctica Scikit-Learn 1</h2>\n",
    "\n",
    "## Docentes\n",
    "\n",
    " - José Francisco Diez Pastor\n",
    "\n",
    "## Estudiantes (1-2)\n",
    "\n",
    "- Víctor Gonzáelez del Campo\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6xs0EocFFKj"
   },
   "source": [
    "<a id=\"index\"></a>\n",
    "## Tareas\n",
    "\n",
    "1. [Carga de los datos. **(3 Puntos)**](#1)\n",
    "2. [Crea una función que evalua conjuntos desbalanceados.**(1 Puntos)**](#2)\n",
    "3. [Evaluar clasificadores con funciones de evaluación propias **(4 Puntos)**](#3)\n",
    "4. [Experimentos con regresores. **(2 Puntos)**](#4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WawCLuDFFFKj"
   },
   "source": [
    "###  Tarea 1. Carga de los datos (3 Puntos)<a id=\"1\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "\n",
    "Realizar 4 funciones, con su documentación (la documentación debe describir que hace la función, los argumentos de entrada y los valores de retorno).\n",
    "- `load_insurance()`.\n",
    "- `load_brest_cancer()`.\n",
    "- `load_heart_failure()`.\n",
    "- `load_mortality()`.\n",
    "\n",
    "Estas funciones se van a crear a imagen y semajanza de las funciones que sirven para cargar los datos de ejemplo en `sklearn`.\n",
    "\n",
    "En `sklearn` las funciones de carga de datos devuelven un diccionario con una clave `data` asociada a los atributos independientes y una clave `target`asociada a la variable dependiente o clase.\n",
    "\n",
    "```Python\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes_dataset = load_diabetes()\n",
    "X = diabetes_dataset[\"data\"]\n",
    "y = diabetes_dataset[\"target\"]\n",
    "\n",
    "print(X[:5])\n",
    "print(y[:5])\n",
    "```\n",
    "\n",
    "```\n",
    "[[ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076 -0.04340085 -0.00259226  0.01990749 -0.01764613]\n",
    " [-0.00188202 -0.04464164 -0.05147406 -0.02632753 -0.00844872 -0.01916334  0.07441156 -0.03949338 -0.06833155 -0.09220405]\n",
    " [ 0.08529891  0.05068012  0.04445121 -0.00567042 -0.04559945 -0.03419447 -0.03235593 -0.00259226  0.00286131 -0.02593034]\n",
    " [-0.08906294 -0.04464164 -0.01159501 -0.03665608  0.01219057  0.02499059 -0.03603757  0.03430886  0.02268774 -0.00936191]\n",
    " [ 0.00538306 -0.04464164 -0.03638469  0.02187239  0.00393485  0.01559614  0.00814208 -0.00259226 -0.03198764 -0.04664087]]\n",
    "[151.  75. 141. 206. 135.]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0lz6mjfFFKj"
   },
   "source": [
    "Se quiere que las 4 funciones solicitadas trabajen de una manera análoga.\n",
    "\n",
    "Consideraciones:\n",
    "- Algunos datasets tienen atributos nominales y se quieren transformar a binarios utilizando la técnica de one hot encoding. En Python es muy fácil usando el método `get_dummies()` de Pandas.\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "- En los datasets binarios (mortality, breast cancer y heart failure) queremos que los dos posibles valores de las clases sean `t`y `f`. La clase positiva (`t`) va a ser siempre la minoritaria.\n",
    "- Las 4 funciones son muy similares, así que puedes pensar como implementarlas para evitar código duplicado.\n",
    "\n",
    "Pasos:\n",
    "1. Carga los datos, utiliza Pandas para ello, por ejemplo `read_csv`.\n",
    "2. Separa los atributos del valor a predecir o clase.\n",
    "3. Convierte los atributos nominales a binarios con get_dummies.\n",
    "4. En el caso de los conjuntos de clasificación fuerza que las clases sean `t`y `f`y `t`sea la clase minoritaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO8oRuz5FFKj"
   },
   "source": [
    "#### Resultado esperado\n",
    "![imagen.png](attachment:imagen.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "PEoEpgz3FFKk",
    "outputId": "c4cc0980-6c1c-4a7b-e5ec-cbcf14ccb52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________Diabetes________\n",
      "Primera fila [ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076\n",
      " -0.04340085 -0.00259226  0.01990749 -0.01764613]\n",
      "Medias X [-1.44429466e-18  2.54321451e-18 -2.25592546e-16 -4.85408596e-17\n",
      " -1.42859580e-17  3.89881064e-17 -6.02836031e-18 -1.78809958e-17\n",
      "  9.24348582e-17  1.35176953e-17]\n",
      "Primeras ys [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
      "Media y 152.13348416289594\n",
      "________Insurance________\n",
      "Primera fila [19.  27.9  0.   1.   0.   0.   1.   0.   0.   0.   1. ]\n",
      "Medias X [39.20702541 30.66339686  1.09491779  0.49476831  0.50523169  0.79521674\n",
      "  0.20478326  0.24215247  0.24289985  0.27204783  0.24289985]\n",
      "Primeras ys              0\n",
      "0  16884.92400\n",
      "1   1725.55230\n",
      "2   4449.46200\n",
      "3  21984.47061\n",
      "4   3866.85520\n",
      "5   3756.62160\n",
      "6   8240.58960\n",
      "7   7281.50560\n",
      "8   6406.41070\n",
      "9  28923.13692\n",
      "Media y 0    13270.422265\n",
      "dtype: float64\n",
      "________Cancer________\n",
      "Primera fila [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "Medias X [1.41272917e+01 1.92896485e+01 9.19690334e+01 6.54889104e+02\n",
      " 9.63602812e-02 1.04340984e-01 8.87993158e-02 4.89191459e-02\n",
      " 1.81161863e-01 6.27976098e-02 4.05172056e-01 1.21685343e+00\n",
      " 2.86605923e+00 4.03370791e+01 7.04097891e-03 2.54781388e-02\n",
      " 3.18937163e-02 1.17961371e-02 2.05422988e-02 3.79490387e-03\n",
      " 1.62691898e+01 2.56772232e+01 1.07261213e+02 8.80583128e+02\n",
      " 1.32368594e-01 2.54265044e-01 2.72188483e-01 1.14606223e-01\n",
      " 2.90075571e-01 8.39458172e-02]\n",
      "Primeras ys ['t' 't' 't' 't' 't' 't' 't' 't' 't' 't']\n",
      "Frecuencias y (array(['f', 't'], dtype=object), array([357, 212]))\n",
      "________Heart Failure________\n",
      "Primera fila [7.50e+01 0.00e+00 5.82e+02 0.00e+00 2.00e+01 1.00e+00 2.65e+05 1.90e+00\n",
      " 1.30e+02 1.00e+00 0.00e+00 4.00e+00]\n",
      "Medias X [6.08338930e+01 4.31438127e-01 5.81839465e+02 4.18060201e-01\n",
      " 3.80836120e+01 3.51170569e-01 2.63358029e+05 1.39387960e+00\n",
      " 1.36625418e+02 6.48829431e-01 3.21070234e-01 1.30260870e+02]\n",
      "Primeras ys ['t' 't' 't' 't' 't' 't' 't' 't' 't' 't']\n",
      "Frecuencias y (array(['f', 't'], dtype=object), array([203,  96]))\n",
      "________Survival________\n",
      "Primera fila [8.44649e+03 1.49908e+03 2.00000e+00 5.00000e+00 5.00000e+00 4.20000e+01\n",
      " 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00]\n",
      "Medias X [8.29916573e+05 1.35772964e+04 8.67269111e+00 2.67606365e+01\n",
      " 9.69699066e+00 1.42183414e+02 8.55153926e-01 8.35091664e-01\n",
      " 5.88031823e-03 6.91802145e-02 8.91560014e-02 6.91802145e-04\n",
      " 1.06796956e-01 5.11674161e-01]\n",
      "Primeras ys ['f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f']\n",
      "Frecuencias y (array(['f', 't'], dtype=object), array([9422, 2142]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_dataset(train_data,target_data,is_classification):\n",
    "    \"\"\"\n",
    "    Convierte los atributos nominales a binarios con one hot encoding si es necesario.\n",
    "\n",
    "    Argumentos:\n",
    "    train_data: DataFrame. Datos de atributos independientes.\n",
    "    target_data: Series o array. Datos de la variable dependiente.\n",
    "    is_classification: bool. Indica si el problema es de clasificación binaria.\n",
    "\n",
    "    Retorna:\n",
    "    Un diccionario con 'data' para los atributos independientes y 'target' para la variable dependiente.\n",
    "    \"\"\"\n",
    "\n",
    "    # Conviértelo a un DataFrame de Pandas\n",
    "    target_data = pd.DataFrame(target_data)\n",
    "\n",
    "\n",
    "    if is_classification:\n",
    "        # Convertir la variable objetivo a clases t y f\n",
    "        frecuencias = target_data.value_counts()\n",
    "\n",
    "        valores = frecuencias.index\n",
    "        apariciones = frecuencias.values\n",
    "\n",
    "        menos_frecuente = valores[apariciones.argmin()]\n",
    "        mas_frecuente = valores[apariciones.argmax()]\n",
    "      \n",
    "        target_data = target_data.replace(menos_frecuente,\"t\").replace(mas_frecuente,\"f\").values.ravel()\n",
    "\n",
    "        \n",
    "\n",
    "    # Convierte los atributos nominales a binarios con get_dummies\n",
    "    X = pd.get_dummies(train_data).astype(float)\n",
    "\n",
    "    return {'data': X.values, 'target': target_data}\n",
    "\n",
    "\n",
    "\n",
    "def classification(target_data):\n",
    "    \"\"\"\n",
    "    Devuelve true o false, en caso de ser problema de clasificacion binaria.\n",
    "    \"\"\"\n",
    "    # Verifica si el problema es de clasificación binaria\n",
    "    num_unique_values = len(np.unique(target_data))\n",
    "    return num_unique_values == 2\n",
    "\n",
    "\n",
    "def load_data(df,clase):\n",
    "    \"\"\"\n",
    "    Se separa la clase de los atributos para la columna determinada como clase\n",
    "    \"\"\"\n",
    "    # Selecciona los atributos independientes eliminando la clase (target)\n",
    "    train_data = df.drop([clase], axis=1)\n",
    "\n",
    "    # Selecciona la variable objetivo (target)\n",
    "    target_data = df[clase].values\n",
    "\n",
    "    return train_data, target_data\n",
    "    \n",
    "\n",
    "\n",
    "def load_insurance():\n",
    "    \"\"\"\n",
    "    Carga los datos del conjunto de datos 'insurance.csv' y realiza la transformación necesaria de los atributos y las etiquetas de clase.\n",
    "\n",
    "    Retorna:\n",
    "    Un diccionario con 'data' para los atributos independientes y 'target' para la variable dependiente.\n",
    "    \"\"\"\n",
    "    # Carga los datos del archivo CSV\n",
    "    df = pd.read_csv('/home/conflictor/Escritorio/UNI/UBU/Mineria-de-Datos/Practicas/P2/2024_SK1_CLASS_REG/data/insurance.csv')\n",
    "\n",
    "    #cargamos train_data y target_data\n",
    "    train_data, target_data = load_data(df,\"charges\")\n",
    "\n",
    "    is_classification = classification(target_data)\n",
    "\n",
    "    # Realiza la carga del conjunto de datos y aplica transformaciones necesarias\n",
    "    return load_dataset(train_data, target_data, is_classification)\n",
    "\n",
    "\n",
    "def load_cancer():\n",
    "    \"\"\"\n",
    "    Carga los datos del conjunto de datos 'wisconsin.csv' y realiza la transformación necesaria de los atributos y las etiquetas de clase.\n",
    "\n",
    "    Retorna:\n",
    "    Un diccionario con 'data' para los atributos independientes y 'target' para la variable dependiente.\n",
    "    \"\"\"\n",
    "    # Carga los datos del archivo CSV\n",
    "    df = pd.read_csv('/home/conflictor/Escritorio/UNI/UBU/Mineria-de-Datos/Practicas/P2/2024_SK1_CLASS_REG/data/wisconsin.csv')\n",
    "\n",
    "    #cargamos train_data y target_data\n",
    "    train_data, target_data = load_data(df,\"diagnosis\")\n",
    "\n",
    "    is_classification = classification(target_data)\n",
    "\n",
    "    # Realiza la carga del conjunto de datos y aplica transformaciones necesarias\n",
    "    return load_dataset(train_data, target_data, is_classification)\n",
    "\n",
    "\n",
    "def load_heart_failure():\n",
    "    \"\"\"\n",
    "    Carga los datos del conjunto de datos 'heart_failure_clinical_records_dataset.csv' y realiza la transformación necesaria de los atributos y las etiquetas de clase.\n",
    "\n",
    "    Retorna:\n",
    "    Un diccionario con 'data' para los atributos independientes y 'target' para la variable dependiente.\n",
    "    \"\"\"\n",
    "    # Carga los datos del archivo CSV\n",
    "    df = pd.read_csv('/home/conflictor/Escritorio/UNI/UBU/Mineria-de-Datos/Practicas/P2/2024_SK1_CLASS_REG/data/heart_failure_clinical_records_dataset.csv')\n",
    "\n",
    "    #cargamos train_data y target_data\n",
    "    train_data, target_data = load_data(df,\"DEATH_EVENT\")\n",
    "\n",
    "    is_classification = classification(target_data)\n",
    "\n",
    "    # Realiza la carga del conjunto de datos y aplica transformaciones necesarias\n",
    "    return load_dataset(train_data, target_data, is_classification)\n",
    "\n",
    "\n",
    "def load_survival():\n",
    "\n",
    "    \"\"\"\n",
    "    Carga los datos del all.csv y realiza las transformaciones necesarias.\n",
    "    \n",
    "    Retorna:\n",
    "        Un diccionario con 'data' para los atributos independientes y 'target' para la variable dependiente.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Carga los datos\n",
    "    df = pd.read_csv('/home/conflictor/Escritorio/UNI/UBU/Mineria-de-Datos/Practicas/P2/2024_SK1_CLASS_REG/data/all.csv')\n",
    "\n",
    "    #cargamos train_data y target_data\n",
    "    train_data, target_data = load_data(df,\"Class\")\n",
    "\n",
    "    is_classification = classification(target_data)\n",
    "\n",
    "    return load_dataset(train_data,target_data,is_classification)\n",
    "\n",
    "\n",
    "\n",
    "datasets = [load_diabetes(),load_insurance(),\n",
    "            load_cancer(), load_heart_failure(),load_survival()]\n",
    "nombres = [\"Diabetes\", \"Insurance\",\n",
    "           \"Cancer\",\"Heart Failure\",\"Survival\"]\n",
    "\n",
    "for dataset,nombre in zip(datasets,nombres):\n",
    "\n",
    "    X = dataset[\"data\"]\n",
    "    y = dataset[\"target\"]\n",
    "    print(f\"________{nombre}________\")\n",
    "    print(\"Primera fila\",X[0])\n",
    "    print(\"Medias X\",X.mean(axis=0))\n",
    "    print(\"Primeras ys\",y[:10])\n",
    "    if nombre in [\"Diabetes\", \"Insurance\"]:\n",
    "        print(\"Media y\",y.mean())\n",
    "    else:\n",
    "        print(\"Frecuencias y\",np.unique(y, return_counts=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBpMXK2JFFKl"
   },
   "source": [
    "### Tarea 2.Crea una función que evalua conjuntos desbalanceados (1 Puntos)<a id=\"2\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "En un conjunto desbalanceado, en el que el número de ejemplos de una clase es muy superior al número de ejemplos de la otra, no es tan útil utilizar el `accuracy_score` (tasa de acierto). Por ejemplo podría darse el caso de un conjunto de datos en el que tuviesemos un 99% de ejemplos pertenecientes a pacientes negativos en una determinada enfermedad y un 1% en positivos. Un clasificador poco inteligente que siempre predijese la clase mayoritaria acertaría el 99% de las veces pero no sería nada útil.\n",
    "\n",
    "Para esos casos se utilizan medidas derivadas de la matriz de confusión.\n",
    "\n",
    "|                 | Positiva Pred | Negativa Pred   |\n",
    "|-----------------|---------------|-----------------|\n",
    "| Positiva Real   |      TP       |      FN         |\n",
    "| Negativa Real   |      FP       |      TN         |\n",
    "\n",
    "- precision = TP / (TP + FP)\n",
    "- recall = TP / (TP + FN)\n",
    "\n",
    "- f1 = 2 (precision x recall) / (precision + recall)\n",
    "\n",
    "- TNR = TN / (TN+FN)\n",
    "- TPR = TP / (TP+FP)\n",
    "\n",
    "- balanced accuracy = (TNR + TPR)/2\n",
    "\n",
    "\n",
    "Como los conjuntos de datos de clasificación que se van a usar en esta práctica son desbalanceados, se pide implementar una función para la tasa de acierto balanceada\n",
    "\n",
    "Realizar y documentar una función:\n",
    "- `my_balanced_accuracy`. Recibe `y_true` los valores de las clases correctos, `y_pred` las predicciones. Devuelve la tasa de acierto balanceada.\n",
    "\n",
    "Se puede comparar su buen funcionamiento comparandola con la oficial de `Sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 1, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [\"F\", \"T\", \"F\", \"F\", \"T\", \"F\", \"F\", \"T\"]\n",
    "y_pred = [\"F\", \"T\", \"F\", \"F\", \"F\", \"T\",\"T\", \"T\"]\n",
    "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pUh6ppeUFFKm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#sklearn.metrics.confusion_matrix¶\n",
    "\n",
    "def my_balanced_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula la tasa de acierto balanceada.\n",
    "\n",
    "    Argumentos:\n",
    "    y_true: array. Valores de las clases correctos.\n",
    "    y_pred: array. Predicciones.\n",
    "\n",
    "    Retorna:\n",
    "    La tasa de acierto balanceada.\n",
    "    \"\"\"\n",
    "    \n",
    "    TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)    \n",
    "    f1 = 2*(precision * recall) / (precision + recall)\n",
    "    TNR = TN / (TN+FN)\n",
    "    TPR = TP / (TP+FP)\n",
    "    \n",
    "    return (TNR + TPR)/2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8VwrlGUYFFKm",
    "outputId": "9ad16787-c694-4fd5-82a3-028e30ffead7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "0.625\n",
      "0.7083333333333333\n",
      "0.7083333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [0, 1, 0, 0, 1, 0]\n",
    "y_pred = [0, 1, 0, 0, 0, 1]\n",
    "\n",
    "\n",
    "\n",
    "print(balanced_accuracy_score(y_true, y_pred))\n",
    "print(my_balanced_accuracy(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "y_true = [\"F\", \"T\", \"F\", \"F\", \"T\", \"F\",\"T\"]\n",
    "y_pred = [\"F\", \"T\", \"F\", \"F\", \"F\", \"T\",\"T\"]\n",
    "\n",
    "print(balanced_accuracy_score(y_true, y_pred))\n",
    "print(my_balanced_accuracy(y_true, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8au4aFRFFKm"
   },
   "source": [
    "### Tarea 3. Evaluar clasificadores con funciones de evaluación propias. (4 Puntos)<a id=\"3\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Crear y documenta la función:\n",
    "\n",
    "- `evalua(dataset, method, folds, metric)` La métrica indicada para cada una de las folds indicadas. Utilizando el dataset (diccionario con clave data y clave tarjet) y el método de clasificación indicado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXgt7lp7FFKm"
   },
   "source": [
    "```Python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "dataset = load_cancer()\n",
    "\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "bal_acc_scorer = make_scorer(my_balanced_accuracy)\n",
    "\n",
    "\n",
    "evalua(dataset,KNeighborsClassifier(),10,bal_acc_scorer)\n",
    "```\n",
    "\n",
    "Devuelve\n",
    "\n",
    "```\n",
    "array([0.90324675, 0.84935065, 0.88690476, 0.95238095, 0.93849206,\n",
    "       0.92460317, 0.96230159, 0.91468254, 0.92063492, 0.96190476])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OW26dw9sFFKn"
   },
   "outputs": [],
   "source": [
    "def evalua(dataset, method, folds, metric):\n",
    "    \"\"\"\n",
    "    Evalúa clasificadores utilizando una métrica personalizada.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "        dataset (dict): Diccionario con claves \"data\" y \"target\".\n",
    "        \n",
    "        method: Clasificador a evaluar (por ejemplo, KNeighborsClassifier()).\n",
    "        \n",
    "        folds (int): Número de pliegues para la validación cruzada.\n",
    "        \n",
    "        metric: Métrica personalizada (por ejemplo, balanced_accuracy_score).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array con las métricas calculadas para cada fold.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    scores = cross_val_score(method, X, y, cv=folds, scoring=metric)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BzwJFzbGFFKn",
    "outputId": "d9c076b2-93eb-414a-f421-e307b0d584d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6623097  0.65111878 0.64738729 0.63147587 0.67129764 0.65507646\n",
      " 0.67241783 0.6643071  0.67020889 0.68259804]\n",
      " \n",
      "[0.78629631 0.78243012 0.78257896 0.7735279  0.78869303 0.7848541\n",
      " 0.79067374 0.78871322 0.79002364 0.79981939]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "dataset = load_heart_failure()\n",
    "\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "bal_acc_scorer = make_scorer(my_balanced_accuracy)\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')  # O el tipo de promedio que desees usar\n",
    "\n",
    "e1 = evalua(dataset,KNeighborsClassifier(),10,bal_acc_scorer)\n",
    "e2 = evalua(dataset,KNeighborsClassifier(),10,f1_scorer)\n",
    "print(e1)\n",
    "print(\" \")\n",
    "print(e2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQSzyz9aFFKn"
   },
   "source": [
    "Haz una una tabla de resultados para cada una de las 3 medidas: tasa de acierto, tasa de acierto balanceada, F1.\n",
    "\n",
    "![imagen.png](attachment:imagen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUPOiGJYFFKo"
   },
   "source": [
    "#### Comentarios\n",
    "\n",
    "1. Trata de hacer la tabla automáticamente utilizando DataFrames de Pandas.\n",
    "2. Prueba varios clasificadores por lo menos los que se ven en la tabla: Vecinos más cercanos y árbol de decisión.\n",
    "2. Los ensembles son conjuntos de clasificadores. Los ensembles pueden a menudo obtener mejores resultados que los clasificadores base de los que están formados (Investiga que ensembles hay en Sklearn y pruebalos).\n",
    "    - Las ganancias obtenidas al añadir clasificadores a un ensemble son cada vez menores a medida que el ensemble crece.\n",
    "3. Hay muchas estrategías para lidiar con conjuntos de datos desequilibrados. Una es reducir el tamaño de la clase mayoritaria eliminando ejemplos de forma aleatoria (Random Undersampling) y otra es aumentar el tamaño de la clase minoritaria creando ejemplos artificiales (SMOTE, Oversampling)\n",
    "    - Hay ensembles que tienen incorporadas estas estrategias (https://imbalanced-learn.org/stable/references/ensemble.html), puedes intentar probarlas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def crear_dataframe():\n",
    "    # Haz una tabla para cada medida\n",
    "    \n",
    "    datasets = [load_diabetes, load_insurance(),\n",
    "                load_cancer(),load_heart_failure(),load_survival()]\n",
    "    \n",
    "    nombres = [ \"Diabetes\",\"Insurance\",\n",
    "               \"Cancer\",\"Heart Failure\",\"Survival\"]\n",
    "    \n",
    "    #Asignamos los accuracy\n",
    "    acc_scorer = make_scorer(accuracy_score)\n",
    "    bal_acc_scorer = make_scorer(my_balanced_accuracy)\n",
    "    f1_scorer = make_scorer(f1_score, average='weighted')  # O el tipo de promedio que desees usar\n",
    "    \n",
    "    acc_types = [(acc_scorer, \"acc_scorer\"), (bal_acc_scorer, \"bal_acc_scorer\"), (f1_scorer, \"f1_scorer\")]\n",
    "    \n",
    "    all_dataset = []\n",
    "    all_clasificators = []\n",
    "    all_acc = []\n",
    "    all_results = []\n",
    "    \n",
    "    # Crear una lista con dos funciones\n",
    "    clasificadores = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
    "    \n",
    "    for clasificador in clasificadores:\n",
    "        \n",
    "        for dataset, nombre in zip(datasets, nombres):\n",
    "    \n",
    "            for acc, acc_name in acc_types: \n",
    "        \n",
    "                result = evalua(dataset,clasificador,10,acc)\n",
    "        \n",
    "                all_acc.append(acc_name)  # Convertimos el objeto a string para guardar el nombre\n",
    "                all_dataset.append(nombre)\n",
    "                all_clasificators.append(type(clasificador).__name__)  # Obtenemos el nombre de la clase del clasificador\n",
    "    \n",
    "                med_res = sum(result)/len(result)\n",
    "                \n",
    "                all_results.append(med_res)\n",
    "        \n",
    "    df = pd.DataFrame({\"Data\":all_dataset,\"Method\":all_clasificators,\"Acc\":all_acc,\"Result\":all_results})\n",
    "\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Data                Method             Acc    Result\n",
      "0        Diabetes  KNeighborsClassifier      acc_scorer  0.809324\n",
      "1        Diabetes  KNeighborsClassifier  bal_acc_scorer  0.660820\n",
      "2        Diabetes  KNeighborsClassifier       f1_scorer  0.786761\n",
      "3       Insurance  KNeighborsClassifier      acc_scorer  0.809324\n",
      "4       Insurance  KNeighborsClassifier  bal_acc_scorer  0.660820\n",
      "5       Insurance  KNeighborsClassifier       f1_scorer  0.786761\n",
      "6          Cancer  KNeighborsClassifier      acc_scorer  0.809324\n",
      "7          Cancer  KNeighborsClassifier  bal_acc_scorer  0.660820\n",
      "8          Cancer  KNeighborsClassifier       f1_scorer  0.786761\n",
      "9   Heart Failure  KNeighborsClassifier      acc_scorer  0.809324\n",
      "10  Heart Failure  KNeighborsClassifier  bal_acc_scorer  0.660820\n",
      "11  Heart Failure  KNeighborsClassifier       f1_scorer  0.786761\n",
      "12       Survival  KNeighborsClassifier      acc_scorer  0.809324\n",
      "13       Survival  KNeighborsClassifier  bal_acc_scorer  0.660820\n",
      "14       Survival  KNeighborsClassifier       f1_scorer  0.786761\n",
      " \n",
      "             Data                  Method             Acc    Result\n",
      "15       Diabetes  DecisionTreeClassifier      acc_scorer  0.889829\n",
      "16       Diabetes  DecisionTreeClassifier  bal_acc_scorer  0.821635\n",
      "17       Diabetes  DecisionTreeClassifier       f1_scorer  0.891808\n",
      "18      Insurance  DecisionTreeClassifier      acc_scorer  0.890003\n",
      "19      Insurance  DecisionTreeClassifier  bal_acc_scorer  0.820195\n",
      "20      Insurance  DecisionTreeClassifier       f1_scorer  0.891623\n",
      "21         Cancer  DecisionTreeClassifier      acc_scorer  0.889657\n",
      "22         Cancer  DecisionTreeClassifier  bal_acc_scorer  0.818128\n",
      "23         Cancer  DecisionTreeClassifier       f1_scorer  0.890763\n",
      "24  Heart Failure  DecisionTreeClassifier      acc_scorer  0.891213\n",
      "25  Heart Failure  DecisionTreeClassifier  bal_acc_scorer  0.821086\n",
      "26  Heart Failure  DecisionTreeClassifier       f1_scorer  0.889700\n",
      "27       Survival  DecisionTreeClassifier      acc_scorer  0.893289\n",
      "28       Survival  DecisionTreeClassifier  bal_acc_scorer  0.815879\n",
      "29       Survival  DecisionTreeClassifier       f1_scorer  0.893268\n"
     ]
    }
   ],
   "source": [
    "df = crear_dataframe()\n",
    "\n",
    "# Obtén la mitad del DataFrame\n",
    "mitad = len(df) // 2\n",
    "\n",
    "# Primera mitad\n",
    "KNeighborsClassifier = df.iloc[:mitad, :]\n",
    "\n",
    "# Segunda mitad\n",
    "DecisionTreeClassifier = df.iloc[mitad:, :]\n",
    "\n",
    "print(KNeighborsClassifier)\n",
    "print(\" \")\n",
    "print(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxRfkdvnFFKp"
   },
   "source": [
    "### Tarea 4. Experimentos regresores. (2 Puntos)<a id=\"4\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Realiza un experimento similar, pero esta vez utilizando los dos conjuntos de datos de regresión.\n",
    "\n",
    "Utiliza al menos Vecinos más cercanos y árbol de decisión.\n",
    "\n",
    "Investiga los Ensembles existentes en Sklearn para regresión.\n",
    "\n",
    "A la hora de evaluar los regresores puedes usar R2 (sklearn.metrics.r2_score), también llamado coeficiente de determinación.\n",
    "\n",
    "En esa métrica el mejor valor posible es 1.0 y puede obtener valores negativos. Un regresor que siempre devuelve la media, sin tener en cuenta los valores de los atributos obtendría un R2 = 0.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkOgpbfiFFKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MibP4GlhFFKp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
